{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers\n",
    "import numpy as np\n",
    "from datasets import load_dataset, ClassLabel\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnli = load_dataset(\"glue\", \"mnli\")\n",
    "hans = load_dataset(\"hans\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'premise': 'The athletes introduced the tourist .',\n",
       " 'hypothesis': 'The tourist introduced the athletes .',\n",
       " 'label': 1,\n",
       " 'parse_premise': '(ROOT (S (NP (DT The) (NNS athletes)) (VP (VBD introduced) (NP (DT the) (NN tourist))) (. .)))',\n",
       " 'parse_hypothesis': '(ROOT (S (NP (DT The) (NN tourist)) (VP (VBD introduced) (NP (DT the) (NNS athletes))) (. .)))',\n",
       " 'binary_parse_premise': '( ( The athletes ) ( ( introduced ( the tourist ) ) . ) )',\n",
       " 'binary_parse_hypothesis': '( ( The tourist ) ( ( introduced ( the athletes ) ) . ) )',\n",
       " 'heuristic': 'lexical_overlap',\n",
       " 'subcase': 'ln_subject/object_swap',\n",
       " 'template': 'temp1'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hans[\"train\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarize_mnli(dataset, remove_neutral=True):\n",
    "    if remove_neutral:\n",
    "        # neutral class has label 1\n",
    "        dataset = dataset.filter(lambda example: example[\"label\"] != 1)\n",
    "\n",
    "    # change labels of contradiction examples from 2 to 1\n",
    "    def change_label(example):\n",
    "        # convert labels 2 into labels 1. this merges the neutral and contradiction class\n",
    "        example[\"label\"] = 1 if example[\"label\"] == 2 else example[\"label\"]\n",
    "        return example\n",
    "        \n",
    "    # change labels\n",
    "    dataset = dataset.map(change_label)\n",
    "\n",
    "    # change features to reflect the new labels\n",
    "    features = dataset[\"train\"].features.copy()\n",
    "    features[\"label\"] = ClassLabel(num_classes=2, names=['entailment', 'contradiction'], id=None)\n",
    "    dataset = dataset.cast(features)  # overwrite old features\n",
    "        \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnli = binarize_mnli(mnli)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"facebook/opt-125m\"\n",
    "teacher_model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "seed = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'ĠYes' token id: 3216\n",
      "'ĠNo' token id: 440\n"
     ]
    }
   ],
   "source": [
    "yes_id = tokenizer.encode(\" Yes\", add_special_tokens=False)[0]\n",
    "no_id = tokenizer.encode(\" No\", add_special_tokens=False)[0]\n",
    "print(f\"'{tokenizer.convert_ids_to_tokens(yes_id)}' token id: {yes_id}\")\n",
    "print(f\"'{tokenizer.convert_ids_to_tokens(no_id)}' token id: {no_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## IN-CONTEXT LEARNING CODE ##\n",
    "def create_few_shot_context(train_examples, context_indices):\n",
    "    context = \"\"\n",
    "    for idx in context_indices:\n",
    "        example = train_examples[int(idx)]\n",
    "        label_text = \"True\" if example[\"label\"] == 0 else \"False\"\n",
    "        context += f\"{example['premise']}\\nQuestion: {example['hypothesis']} True or False?\\nAnswer: {label_text}\\n\\n\"\n",
    "\n",
    "    return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 100\n",
    "few_shot_size = 6\n",
    "np.random.seed(seed)\n",
    "selected_idx = np.random.choice(len(mnli[\"train\"]), train_size + few_shot_size, replace=False)\n",
    "mnli_few_shot = mnli[\"train\"].select(selected_idx[train_size:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00d29a80579e4a14bcce347f51e26104",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/261802 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64472c8864d54a219110cd5d868778c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6692 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4e34e8eb9bf47fb875615be32ffe80e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6703 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28d5ef67eae04ed3834a9d16fbaa0d6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9796 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "937618d231cd4d1b9a1be8247e1b9305",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9847 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "task_context = \"Given the premise and hypothesis, does the premise entail the hypothesis?\"\n",
    "task_suffix = \"Yes or No? Answer:\"\n",
    "\n",
    "def generate_mnli_prompts(examples, demonstrations):\n",
    "    # teacher model receives task context + premise + hypothesis\n",
    "    examples[\"teacher_prompt\"] = f\"{task_context}\\n{demonstrations}Premise: {examples['premise']}\\nHypothesis: {examples['hypothesis']}\\n{task_suffix}\"\n",
    "    # student model only receives premise + hypothesis\n",
    "    examples[\"student_prompt\"] = f\"{examples['premise']}\\n{examples['hypothesis']}\\n{task_suffix}\"\n",
    "    return examples\n",
    "\n",
    "demonstrations = create_few_shot_context(mnli_few_shot)\n",
    "mnli = mnli.map(generate_mnli_prompts, fn_kwargs={\"demonstrations\": demonstrations})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given the premise and hypothesis, does the premise entail the hypothesis?\n",
      "Premise: yeah that'll be nice i mean that that i think tends to just keep i think stadiums have worked tend to keep people happy\n",
      "Hypothesis: I think that stadiums want to keep people happy.\n",
      "Yes or No? Answer: Yes\n",
      "\n",
      "Premise: oh i bet it doesn't mix well does it\n",
      "Hypothesis: I bet it doesn't mix well, does it?\n",
      "Yes or No? Answer: Yes\n",
      "\n",
      "Premise: Their applicability to case study evaluations outside of settings such as GAO is being explored.\n",
      "Hypothesis: They are exploring the applicability to case study evaluations outside of settings, for example GAO.\n",
      "Yes or No? Answer: Yes\n",
      "\n",
      "Premise: However, there are numerous policy, technical, legal, and human resource issues that are not fully within the control of officials at individual agencies.\n",
      "Hypothesis: Every issue can be controlled.\n",
      "Yes or No? Answer: No\n",
      "\n",
      "Premise: The gaudy red, gold, and white Sam Po Kong Temple stands at the foot of Bukit China, honoring Cheng Ho, the eunuch admiral who in 1409 opened up Melaka to Chinese trade.\n",
      "Hypothesis: Cheng Ho is an admiral who opened Melaka to Chinese trade.\n",
      "Yes or No? Answer: Yes\n",
      "\n",
      "Premise: However, legend says that, just as the executioner raised his sword, a lightning bolt struck and broke it in two.\n",
      "Hypothesis: According to legend, the executioner never picked a sword in his life.\n",
      "Yes or No? Answer: No\n",
      "\n",
      "Premise: One of our number will carry out your instructions minutely.\n",
      "Hypothesis: A member of my team will execute your orders with immense precision.\n",
      "Yes or No? Answer:\n"
     ]
    }
   ],
   "source": [
    "print(mnli[\"train\"][1][\"teacher_prompt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnli_train = mnli[\"train\"].select(selected_idx[:train_size])\n",
    "labels_train = torch.tensor(mnli_train[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0baf887e426948f9920ca9bb378aeaa7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    }
   ],
   "source": [
    "def tokenize_teacher(data):\n",
    "    tokens = tokenizer(data[\"teacher_prompt\"], padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    return tokens\n",
    "\n",
    "\n",
    "tokenized_teacher_mnli_train = mnli_train.map(tokenize_teacher, batched=True)\n",
    "tokenized_teacher_mnli_train.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36000001430511475"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids = tokenized_teacher_mnli_train[\"input_ids\"].to(device)\n",
    "attention_mask = tokenized_teacher_mnli_train[\"attention_mask\"].to(device)\n",
    "teacher_model.eval()\n",
    "\n",
    "teacher_model.to(device)\n",
    "outputs = teacher_model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "logits = outputs.logits\n",
    "    \n",
    "teacher_logits = logits[:, -1, [yes_id, no_id]]\n",
    "teacher_pred = logits[:, -1, [yes_id, no_id]].argmax(dim=-1)\n",
    "teacher_acc = (teacher_pred == labels_train).float().mean().item()\n",
    "teacher_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 1]), tensor([36, 64]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.unique(labels_train, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def context_distillation_loss(labels, teacher_logits, student_logits, alpha=0.5):\n",
    "    with torch.no_grad():\n",
    "        teacher_logprob = torch.nn.functional.softmax(teacher_logits, dim=-1)\n",
    "    student_prob = torch.nn.functional.log_softmax(student_logits, dim=-1)\n",
    "    kl_loss = torch.nn.functional.kl_div(student_prob, teacher_logprob, reduction=\"batchmean\")\n",
    "    ce_loss = torch.nn.functional.cross_entropy(student_logits, labels)\n",
    "    beta = 1 - alpha\n",
    "    cd_loss = alpha * kl_loss + beta * ce_loss\n",
    "    return cd_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5891a38519644df4bd821454f233aa3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/20 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tokenize_student(data):\n",
    "    tokens = tokenizer(data[\"student_prompt\"], padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    return tokens\n",
    "\n",
    "\n",
    "tokenized_student_mnli_train = mnli_train.map(tokenize_student, batched=True)\n",
    "tokenized_student_mnli_train.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, inputs, labels):\n",
    "\n",
    "    \n",
    "    input_ids = inputs[\"input_ids\"]\n",
    "    attention_mask = inputs[\"attention_mask\"]\n",
    "    model.eval()\n",
    "    \n",
    "    outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "    \n",
    "    logits = outputs.logits\n",
    "\n",
    "    target_logits = logits[:, -1, [yes_id, no_id]]\n",
    "    pred = target_logits.argmax(dim=-1)\n",
    "\n",
    "\n",
    "    ce_loss = torch.nn.functional.cross_entropy(target_logits, labels).item()\n",
    "\n",
    "    acc = (pred == labels).float().mean().item()\n",
    "    return ce_loss, acc\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b8ab6b632c34e15a0ae0d4e2f0a3464",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/20 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval_size = 20\n",
    "np.random.seed(seed + 1)\n",
    "selected_idx_eval = np.random.choice(1000, eval_size)\n",
    "\n",
    "mnli_eval = mnli[\"train\"].select(selected_idx_eval)\n",
    "labels_eval = torch.tensor(mnli_eval[\"label\"])\n",
    "tokenized_student_mnli_eval = mnli_eval.map(tokenize_student, batched=True)\n",
    "tokenized_student_mnli_eval.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_student_model(student_model, lr, epochs, train_tokenized, train_labels, validation_tokenized, validation_labels, teacher_logits, target_tokens):\n",
    "    optimizer = torch.optim.Adam(student_model.parameters(), lr=lr)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        input_ids = train_tokenized[\"input_ids\"]\n",
    "        attention_mask = train_tokenized[\"attention_mask\"]\n",
    "\n",
    "        outputs = student_model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "        logits = outputs.logits\n",
    "        student_target_logits = logits[:, -1, target_tokens]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        cd_loss = context_distillation_loss(train_labels, teacher_logits, student_target_logits)\n",
    "        cd_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        pred = student_target_logits.argmax(dim=-1)\n",
    "        train_acc = (pred == train_labels).float().mean().item()\n",
    "        \n",
    "        val_loss, val_acc = evaluate_model(student_model, validation_tokenized, validation_labels)\n",
    "\n",
    "\n",
    "        print(f\"Epoch [{epoch + 1}/{epochs}]\")\n",
    "        print(f\"\\tTraining Loss: {cd_loss.item():.4f}\\t\\tTraining Accuracy: {train_acc:.4f}\")\n",
    "        print(f\"\\tValidation Loss: {val_loss:.4f}\\t\\tValidation Accuracy: {val_acc:.4f}\")\n",
    "\n",
    "    train_loss, train_acc = evaluate_model(student_model, train_tokenized, train_labels)\n",
    "    val_loss, val_acc = evaluate_model(student_model, validation_tokenized, validation_labels)\n",
    "    print(\"Final model\")\n",
    "    print(f\"\\tTraining Loss: {train_loss:.4f}\\t\\tTraining Accuracy: {train_acc:.4f}\")\n",
    "    print(f\"\\tValidation Loss: {val_loss:.4f}\\t\\tValidation Accuracy: {val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/30]\n",
      "\tTraining Loss: 0.3568\t\tTraining Accuracy: 0.5500\n",
      "\tValidation Loss: 0.4873\t\tValidation Accuracy: 0.7500\n",
      "Epoch [2/30]\n",
      "\tTraining Loss: 0.3647\t\tTraining Accuracy: 0.5500\n",
      "\tValidation Loss: 1.0290\t\tValidation Accuracy: 0.2500\n",
      "Epoch [3/30]\n",
      "\tTraining Loss: 0.5094\t\tTraining Accuracy: 0.7500\n",
      "\tValidation Loss: 0.5738\t\tValidation Accuracy: 0.8500\n",
      "Epoch [4/30]\n",
      "\tTraining Loss: 0.2948\t\tTraining Accuracy: 0.9000\n",
      "\tValidation Loss: 0.4685\t\tValidation Accuracy: 0.7500\n",
      "Epoch [5/30]\n",
      "\tTraining Loss: 0.3497\t\tTraining Accuracy: 0.5000\n",
      "\tValidation Loss: 0.4726\t\tValidation Accuracy: 0.7500\n",
      "Epoch [6/30]\n",
      "\tTraining Loss: 0.3339\t\tTraining Accuracy: 0.5000\n",
      "\tValidation Loss: 0.5181\t\tValidation Accuracy: 0.8500\n",
      "Epoch [7/30]\n",
      "\tTraining Loss: 0.2722\t\tTraining Accuracy: 0.7500\n",
      "\tValidation Loss: 0.6347\t\tValidation Accuracy: 0.7500\n",
      "Epoch [8/30]\n",
      "\tTraining Loss: 0.2701\t\tTraining Accuracy: 1.0000\n",
      "\tValidation Loss: 0.7193\t\tValidation Accuracy: 0.3500\n",
      "Epoch [9/30]\n",
      "\tTraining Loss: 0.2929\t\tTraining Accuracy: 1.0000\n",
      "\tValidation Loss: 0.6888\t\tValidation Accuracy: 0.5000\n",
      "Epoch [10/30]\n",
      "\tTraining Loss: 0.2775\t\tTraining Accuracy: 1.0000\n",
      "\tValidation Loss: 0.5991\t\tValidation Accuracy: 0.8000\n",
      "Epoch [11/30]\n",
      "\tTraining Loss: 0.2520\t\tTraining Accuracy: 1.0000\n",
      "\tValidation Loss: 0.5270\t\tValidation Accuracy: 0.8000\n",
      "Epoch [12/30]\n",
      "\tTraining Loss: 0.2471\t\tTraining Accuracy: 0.9000\n",
      "\tValidation Loss: 0.4927\t\tValidation Accuracy: 0.8000\n",
      "Epoch [13/30]\n",
      "\tTraining Loss: 0.2549\t\tTraining Accuracy: 0.8500\n",
      "\tValidation Loss: 0.4833\t\tValidation Accuracy: 0.7500\n",
      "Epoch [14/30]\n",
      "\tTraining Loss: 0.2558\t\tTraining Accuracy: 0.8500\n",
      "\tValidation Loss: 0.4904\t\tValidation Accuracy: 0.8500\n",
      "Epoch [15/30]\n",
      "\tTraining Loss: 0.2463\t\tTraining Accuracy: 1.0000\n",
      "\tValidation Loss: 0.5144\t\tValidation Accuracy: 0.8000\n",
      "Epoch [16/30]\n",
      "\tTraining Loss: 0.2385\t\tTraining Accuracy: 1.0000\n",
      "\tValidation Loss: 0.5485\t\tValidation Accuracy: 0.8000\n",
      "Epoch [17/30]\n",
      "\tTraining Loss: 0.2396\t\tTraining Accuracy: 1.0000\n",
      "\tValidation Loss: 0.5741\t\tValidation Accuracy: 0.7500\n",
      "Epoch [18/30]\n",
      "\tTraining Loss: 0.2442\t\tTraining Accuracy: 1.0000\n",
      "\tValidation Loss: 0.5746\t\tValidation Accuracy: 0.7500\n",
      "Epoch [19/30]\n",
      "\tTraining Loss: 0.2433\t\tTraining Accuracy: 1.0000\n",
      "\tValidation Loss: 0.5531\t\tValidation Accuracy: 0.8000\n",
      "Epoch [20/30]\n",
      "\tTraining Loss: 0.2375\t\tTraining Accuracy: 1.0000\n",
      "\tValidation Loss: 0.5265\t\tValidation Accuracy: 0.8000\n",
      "Epoch [21/30]\n",
      "\tTraining Loss: 0.2341\t\tTraining Accuracy: 1.0000\n",
      "\tValidation Loss: 0.5085\t\tValidation Accuracy: 0.8000\n",
      "Epoch [22/30]\n",
      "\tTraining Loss: 0.2362\t\tTraining Accuracy: 1.0000\n",
      "\tValidation Loss: 0.5028\t\tValidation Accuracy: 0.8500\n",
      "Epoch [23/30]\n",
      "\tTraining Loss: 0.2392\t\tTraining Accuracy: 1.0000\n",
      "\tValidation Loss: 0.5076\t\tValidation Accuracy: 0.8500\n",
      "Epoch [24/30]\n",
      "\tTraining Loss: 0.2385\t\tTraining Accuracy: 1.0000\n",
      "\tValidation Loss: 0.5216\t\tValidation Accuracy: 0.8000\n",
      "Epoch [25/30]\n",
      "\tTraining Loss: 0.2354\t\tTraining Accuracy: 1.0000\n",
      "\tValidation Loss: 0.5423\t\tValidation Accuracy: 0.8000\n",
      "Epoch [26/30]\n",
      "\tTraining Loss: 0.2341\t\tTraining Accuracy: 1.0000\n",
      "\tValidation Loss: 0.5624\t\tValidation Accuracy: 0.8000\n",
      "Epoch [27/30]\n",
      "\tTraining Loss: 0.2357\t\tTraining Accuracy: 1.0000\n",
      "\tValidation Loss: 0.5718\t\tValidation Accuracy: 0.8000\n",
      "Epoch [28/30]\n",
      "\tTraining Loss: 0.2369\t\tTraining Accuracy: 1.0000\n",
      "\tValidation Loss: 0.5658\t\tValidation Accuracy: 0.8000\n",
      "Epoch [29/30]\n",
      "\tTraining Loss: 0.2355\t\tTraining Accuracy: 1.0000\n",
      "\tValidation Loss: 0.5496\t\tValidation Accuracy: 0.8000\n",
      "Epoch [30/30]\n",
      "\tTraining Loss: 0.2334\t\tTraining Accuracy: 1.0000\n",
      "\tValidation Loss: 0.5327\t\tValidation Accuracy: 0.8000\n",
      "Final model\n",
      "\tTraining Loss: 0.3034\t\tTraining Accuracy: 1.0000\n",
      "\tValidation Loss: 0.5327\t\tValidation Accuracy: 0.8000\n"
     ]
    }
   ],
   "source": [
    "student_model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "optimizer = torch.optim.Adam(student_model.parameters(), lr=1e-5)\n",
    "epochs = 30\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    input_ids = tokenized_student_mnli_train[\"input_ids\"]\n",
    "    attention_mask = tokenized_student_mnli_train[\"attention_mask\"]\n",
    "\n",
    "    outputs = student_model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "    logits = outputs.logits\n",
    "    student_logits = logits[:, -1, [yes_id, no_id]]\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    cd_loss = context_distillation_loss(labels_train, teacher_logits, student_logits)\n",
    "    cd_loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    pred = student_logits.argmax(dim=-1)\n",
    "    train_acc = (pred == labels_train).float().mean().item()\n",
    "    \n",
    "    val_loss, val_acc = evaluate_model(student_model, tokenized_student_mnli_eval, labels_eval)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    print(f\"Epoch [{epoch + 1}/{epochs}]\")\n",
    "    print(f\"\\tTraining Loss: {cd_loss.item():.4f}\\t\\tTraining Accuracy: {train_acc:.4f}\")\n",
    "    print(f\"\\tValidation Loss: {val_loss:.4f}\\t\\tValidation Accuracy: {val_acc:.4f}\")\n",
    "\n",
    "train_loss, train_acc = evaluate_model(student_model, tokenized_student_mnli_train, labels_train)\n",
    "val_loss, val_acc = evaluate_model(student_model, tokenized_student_mnli_eval, labels_eval)\n",
    "print(\"Final model\")\n",
    "print(f\"\\tTraining Loss: {train_loss:.4f}\\t\\tTraining Accuracy: {train_acc:.4f}\")\n",
    "print(f\"\\tValidation Loss: {val_loss:.4f}\\t\\tValidation Accuracy: {val_acc:.4f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In-domain Accuracy: 0.5800\n"
     ]
    }
   ],
   "source": [
    "indomain_size = 100\n",
    "np.random.seed(seed)\n",
    "indomain_idx = np.random.choice(mnli[\"validation_mismatched\"].num_rows, indomain_size)\n",
    "indomain = mnli[\"validation_mismatched\"].select(indomain_idx)\n",
    "indomain_labels = torch.tensor(indomain[\"label\"])\n",
    "\n",
    "tokenized_indomain = indomain.map(tokenize_student, batched=True)\n",
    "tokenized_indomain.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\"])\n",
    "loss, acc = evaluate_model(student_model, tokenized_indomain, indomain_labels)\n",
    "print(f\"In-domain Accuracy: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b04b608fea74bfb81635868f435d6ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/30000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f16b66820bf427185145ef84733336e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/30000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# preprocess HANS dataset \n",
    "\n",
    "\n",
    "# add student prompt\n",
    "def generate_hans_prompts(examples):\n",
    "    # student model only receives premise + hypothesis\n",
    "    examples[\"student_prompt\"] = f\"Premise: {examples['premise']}\\nHypothesis: {examples['hypothesis']}\"\n",
    "    return examples\n",
    "\n",
    "hans = hans.map(generate_hans_prompts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e717eedd46dc4e228b602a549284c07c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out-domain Accuracy: 0.4800\n"
     ]
    }
   ],
   "source": [
    "outdomain_size = 100\n",
    "np.random.seed(seed)\n",
    "outdomain_idx = np.random.choice(hans[\"validation\"].num_rows, outdomain_size)\n",
    "outdomain = hans[\"validation\"].select(outdomain_idx)\n",
    "outdomain_labels = torch.tensor(outdomain[\"label\"])\n",
    "\n",
    "tokenized_outdomain = outdomain.map(tokenize_student, batched=True)\n",
    "tokenized_outdomain.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\"])\n",
    "loss, acc = evaluate_model(student_model, tokenized_outdomain, outdomain_labels)\n",
    "print(f\"Out-domain Accuracy: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer functions\n",
    "\n",
    "def tokenize_teacher(data, tokenizer):\n",
    "    tokens = tokenizer(data[\"teacher_prompt\"], padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    return tokens\n",
    "\n",
    "def tokenize_student(data, tokenizer):\n",
    "    tokens = tokenizer(data[\"student_prompt\"], padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    return tokens\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# context distillation loss - KL divergence loss with teacher + cross entropy loss with labels\n",
    "def context_distillation_loss(labels, teacher_logits, student_logits, alpha=0.5, beta=0.5):\n",
    "    with torch.no_grad():\n",
    "        teacher_logprob = torch.nn.functional.softmax(teacher_logits, dim=-1)\n",
    "    student_prob = torch.nn.functional.log_softmax(student_logits, dim=-1)\n",
    "    kl_loss = torch.nn.functional.kl_div(student_prob, teacher_logprob, reduction=\"batchmean\")\n",
    "    ce_loss = torch.nn.functional.cross_entropy(student_logits, labels)\n",
    "    cd_loss = alpha * kl_loss + beta * ce_loss\n",
    "    return cd_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute accuracy and cross entropy loss \n",
    "def evaluate_model(model, inputs, labels, target_token_ids):\n",
    "\n",
    "    \n",
    "    input_ids = inputs[\"input_ids\"]\n",
    "    attention_mask = inputs[\"attention_mask\"]\n",
    "    model.eval()\n",
    "    \n",
    "    outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "    \n",
    "    logits = outputs.logits\n",
    "\n",
    "    target_logits = logits[:, -1, target_token_ids]\n",
    "    pred = target_logits.argmax(dim=-1)\n",
    "\n",
    "\n",
    "    ce_loss = torch.nn.functional.cross_entropy(target_logits, labels).item()\n",
    "\n",
    "    acc = (pred == labels).float().mean().item()\n",
    "    return ce_loss, acc\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_student_model(student_model, lr, epochs, train_tokenized, train_labels, validation_tokenized, validation_labels, \n",
    "                        teacher_logits, target_token_ids, alpha=0.5, beta=0.5):\n",
    "    optimizer = torch.optim.Adam(student_model.parameters(), lr=lr)\n",
    "\n",
    "    best_model = student_model\n",
    "    min_val_loss = None\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        input_ids = train_tokenized[\"input_ids\"]\n",
    "        attention_mask = train_tokenized[\"attention_mask\"]\n",
    "\n",
    "        outputs = student_model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "        logits = outputs.logits\n",
    "        student_target_logits = logits[:, -1, target_token_ids]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        cd_loss = context_distillation_loss(train_labels, teacher_logits, student_target_logits, alpha, beta)\n",
    "        cd_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        pred = student_target_logits.argmax(dim=-1)\n",
    "        train_acc = (pred == train_labels).float().mean().item()\n",
    "        \n",
    "        val_loss, val_acc = evaluate_model(student_model, validation_tokenized, validation_labels, target_token_ids)\n",
    "\n",
    "        if min_val_loss is None or val_loss <= min_val_loss:\n",
    "            min_val_loss = val_loss\n",
    "            best_model = copy.deepcopy(student_model)\n",
    "\n",
    "\n",
    "        print(f\"Epoch [{epoch + 1}/{epochs}]\\tTraining Loss: {cd_loss.item():.4f}\\t\\tTraining Accuracy: {train_acc:.4f}\\t\\tValidation Loss: {val_loss:.4f}\\t\\tValidation Accuracy: {val_acc:.4f}\")\n",
    "\n",
    "    train_loss, train_acc = evaluate_model(best_model, train_tokenized, train_labels, target_token_ids)\n",
    "    val_loss, val_acc = evaluate_model(best_model, validation_tokenized, validation_labels, target_token_ids)\n",
    "    print(f\"Best model:\\tTraining Loss: {train_loss:.4f}\\t\\tTraining Accuracy: {train_acc:.4f}\\t\\tValidation Loss: {val_loss:.4f}\\t\\tValidation Accuracy: {val_acc:.4f}\")\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model and compute in-domain and out-domain accuracies\n",
    "def compute_model_performance(model_name, train_dataset, validation_dataset, indomain_dataset, outdomain_dataset, \n",
    "                              epochs, lr, alpha=0.5, beta=0.5):\n",
    "    print(f\"Model: {model_name}\")\n",
    "    teacher_model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    # compare yes/no token logit/probability for context distillation\n",
    "    yes_id = tokenizer.convert_tokens_to_ids(\"yes\")\n",
    "    no_id = tokenizer.convert_tokens_to_ids(\"no\")\n",
    "    target_token_ids = [yes_id, no_id]\n",
    "    \n",
    "    # Pre-computing teacher logits to train student\n",
    "    tokenized_teacher_train = train_dataset.map(tokenize_teacher, fn_kwargs={\"tokenizer\": tokenizer}, batched=True)\n",
    "    tokenized_teacher_train.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\"])\n",
    "\n",
    "    teacher_input_ids = tokenized_teacher_train[\"input_ids\"]\n",
    "    teacher_attention_mask = tokenized_teacher_train[\"attention_mask\"]\n",
    "    \n",
    "    # disable gradients\n",
    "    teacher_model.eval()\n",
    "    teacher_logits = teacher_model(input_ids=teacher_input_ids, attention_mask=teacher_attention_mask).logits\n",
    "\n",
    "    \n",
    "    # extract yes/no logits\n",
    "    teacher_target_logits = teacher_logits[:, -1, target_token_ids]\n",
    "    teacher_pred = teacher_target_logits.argmax(dim=-1)\n",
    "    train_labels = torch.tensor(train_dataset[\"label\"])\n",
    "    teacher_acc = (teacher_pred == train_labels).float().mean().item()\n",
    "    print(f\"Teacher Training Accuracy: {teacher_acc}\")\n",
    "\n",
    "    # train student model\n",
    "    tokenized_student_train = train_dataset.map(tokenize_student, fn_kwargs={\"tokenizer\": tokenizer}, batched=True)\n",
    "    tokenized_student_train.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\"])\n",
    "\n",
    "    tokenized_student_val = validation_dataset.map(tokenize_student, fn_kwargs={\"tokenizer\": tokenizer}, batched=True)\n",
    "    tokenized_student_val.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\"])\n",
    "\n",
    "    print(\"Training student model:\")\n",
    "    student_model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "    validation_labels = torch.tensor(validation_dataset[\"label\"])\n",
    "    student_model = train_student_model(student_model, lr, epochs, tokenized_student_train, train_labels, tokenized_student_val, validation_labels, \n",
    "                        teacher_target_logits, target_token_ids, alpha, beta)\n",
    "\n",
    "    # compute in-domain accuracy\n",
    "    tokenized_indomain = indomain_dataset.map(tokenize_student, fn_kwargs={\"tokenizer\": tokenizer}, batched=True)\n",
    "    tokenized_indomain.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\"])\n",
    "    indomain_labels = torch.tensor(indomain_dataset[\"label\"])\n",
    "    id_loss, id_acc = evaluate_model(student_model, tokenized_indomain, indomain_labels, target_token_ids)\n",
    "    print(f\"In-domain Accuracy: {id_acc:.4f}\")\n",
    "\n",
    "    # compute out-domain accuracy\n",
    "    tokenized_outdomain = outdomain_dataset.map(tokenize_student, fn_kwargs={\"tokenizer\": tokenizer}, batched=True)\n",
    "    tokenized_outdomain.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\"])\n",
    "    outdomain_labels = torch.tensor(outdomain_dataset[\"label\"])\n",
    "    od_loss, od_acc = evaluate_model(student_model, tokenized_outdomain, outdomain_labels, target_token_ids)\n",
    "    print(f\"Out-domain Accuracy: {od_acc:.4f}\")\n",
    "\n",
    "    return {\n",
    "        \"In-domain Accuracy\": id_acc,\n",
    "        \"Out-domain Accuracy\": od_acc,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnli = load_dataset(\"glue\", \"mnli\")\n",
    "hans = load_dataset(\"hans\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing MNLI dataset\n",
    "\n",
    "\n",
    "# convert MNLI into binary classification\n",
    "def binarize_mnli(dataset, remove_neutral=True):\n",
    "    if remove_neutral:\n",
    "        # neutral class has label 1\n",
    "        dataset = dataset.filter(lambda example: example[\"label\"] != 1)\n",
    "\n",
    "    # change labels of contradiction examples from 2 to 1\n",
    "    def change_label(example):\n",
    "        # convert labels 2 into labels 1. this merges the neutral and contradiction class\n",
    "        example[\"label\"] = 1 if example[\"label\"] == 2 else example[\"label\"]\n",
    "        return example\n",
    "        \n",
    "    # change labels\n",
    "    dataset = dataset.map(change_label)\n",
    "\n",
    "    # change features to reflect the new labels\n",
    "    features = dataset[\"train\"].features.copy()\n",
    "    features[\"label\"] = ClassLabel(num_classes=2, names=['entailment', 'contradiction'], id=None)\n",
    "    dataset = dataset.cast(features)  # overwrite old features\n",
    "        \n",
    "    return dataset\n",
    "\n",
    "# add teacher and student prompts\n",
    "task_context = \"Given the premise and hypothesis: reply 'yes' if the premise entails the hypothesis, or 'no' otherwise\"\n",
    "\n",
    "def generate_mnli_prompts(examples):\n",
    "    # teacher model receives task context + premise + hypothesis\n",
    "    examples[\"teacher_prompt\"] = f\"{task_context}\\nPremise: '{examples['premise']}'\\nHypothesis: '{examples['hypothesis']}'\"\n",
    "    # student model only receives premise + hypothesis\n",
    "    examples[\"student_prompt\"] = f\"Premise: {examples['premise']}\\nHypothesis: {examples['hypothesis']}\"\n",
    "    return examples\n",
    "\n",
    "\n",
    "mnli = binarize_mnli(mnli)\n",
    "mnli = mnli.map(generate_mnli_prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess HANS dataset \n",
    "\n",
    "\n",
    "# add student prompt\n",
    "def generate_hans_prompts(examples):\n",
    "    # student model only receives premise + hypothesis\n",
    "    examples[\"student_prompt\"] = f\"Premise: {examples['premise']}\\nHypothesis: {examples['hypothesis']}\"\n",
    "    return examples\n",
    "\n",
    "hans = hans.map(generate_hans_prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate train, validation, indomain, outdomain datasets\n",
    "\n",
    "seed = 100\n",
    "np.random.seed(seed)\n",
    "\n",
    "\n",
    "# train dataset (MNLI train)\n",
    "train_size = 10     # few shot examples\n",
    "train_idx = np.random.choice(mnli[\"train\"].num_rows, train_size)\n",
    "train_dataset = mnli[\"train\"].select(train_idx)\n",
    "\n",
    "# validation dataset (MNLI validation matched)\n",
    "val_size = 100\n",
    "val_idx = np.random.choice(mnli[\"validation_matched\"].num_rows, val_size)\n",
    "validation_dataset = mnli[\"validation_matched\"].select(val_idx)\n",
    "\n",
    "# indomain dataset (MNLI validation mismatched)\n",
    "indomain_size = 100\n",
    "indomain_idx = np.random.choice(mnli[\"validation_mismatched\"].num_rows, indomain_size)\n",
    "indomain_dataset = mnli[\"validation_mismatched\"].select(indomain_idx)\n",
    "\n",
    "# outdomain (HANS validation)\n",
    "outdomain_size = 100\n",
    "outdomain_idx = np.random.choice(hans[\"validation\"].num_rows, outdomain_size)\n",
    "outdomain_dataset = hans[\"validation\"].select(outdomain_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: facebook/opt-125m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6b08ef6ec204e8fa5e4d6b4158cdc78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teacher Training Accuracy: 0.4000000059604645\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dbc2dbe74754f4eb6da42bc7c1fcfb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cbbea20309a4dc38310007130e207df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training student model:\n",
      "Epoch [1/30]\tTraining Loss: 0.5088\t\tTraining Accuracy: 0.2000\t\tValidation Loss: 0.7420\t\tValidation Accuracy: 0.5100\n",
      "Epoch [2/30]\tTraining Loss: 0.6467\t\tTraining Accuracy: 0.5000\t\tValidation Loss: 0.7058\t\tValidation Accuracy: 0.5000\n",
      "Epoch [3/30]\tTraining Loss: 0.3292\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 0.7978\t\tValidation Accuracy: 0.5200\n",
      "Epoch [4/30]\tTraining Loss: 0.5868\t\tTraining Accuracy: 0.5000\t\tValidation Loss: 0.7044\t\tValidation Accuracy: 0.5300\n",
      "Epoch [5/30]\tTraining Loss: 0.2691\t\tTraining Accuracy: 0.9000\t\tValidation Loss: 0.7090\t\tValidation Accuracy: 0.5200\n",
      "Epoch [6/30]\tTraining Loss: 0.4389\t\tTraining Accuracy: 0.9000\t\tValidation Loss: 0.8289\t\tValidation Accuracy: 0.5200\n",
      "Epoch [7/30]\tTraining Loss: 0.3332\t\tTraining Accuracy: 0.6000\t\tValidation Loss: 0.8547\t\tValidation Accuracy: 0.5200\n",
      "Epoch [8/30]\tTraining Loss: 0.3336\t\tTraining Accuracy: 0.5000\t\tValidation Loss: 0.7445\t\tValidation Accuracy: 0.4300\n",
      "Epoch [9/30]\tTraining Loss: 0.3071\t\tTraining Accuracy: 0.9000\t\tValidation Loss: 0.7122\t\tValidation Accuracy: 0.5400\n",
      "Epoch [10/30]\tTraining Loss: 0.2600\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 0.7236\t\tValidation Accuracy: 0.5400\n",
      "Epoch [11/30]\tTraining Loss: 0.2704\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 0.7025\t\tValidation Accuracy: 0.5300\n",
      "Epoch [12/30]\tTraining Loss: 0.2619\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 0.6981\t\tValidation Accuracy: 0.5200\n",
      "Epoch [13/30]\tTraining Loss: 0.2582\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 0.7006\t\tValidation Accuracy: 0.5300\n",
      "Epoch [14/30]\tTraining Loss: 0.2574\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 0.7055\t\tValidation Accuracy: 0.5500\n",
      "Epoch [15/30]\tTraining Loss: 0.2604\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 0.6988\t\tValidation Accuracy: 0.5300\n",
      "Epoch [16/30]\tTraining Loss: 0.2587\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 0.6925\t\tValidation Accuracy: 0.5400\n",
      "Epoch [17/30]\tTraining Loss: 0.2582\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 0.7005\t\tValidation Accuracy: 0.5400\n",
      "Epoch [18/30]\tTraining Loss: 0.2560\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 0.7110\t\tValidation Accuracy: 0.5300\n",
      "Epoch [19/30]\tTraining Loss: 0.2588\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 0.7052\t\tValidation Accuracy: 0.5100\n",
      "Epoch [20/30]\tTraining Loss: 0.2579\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 0.6987\t\tValidation Accuracy: 0.5200\n",
      "Epoch [21/30]\tTraining Loss: 0.2569\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 0.7004\t\tValidation Accuracy: 0.5200\n",
      "Epoch [22/30]\tTraining Loss: 0.2560\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 0.7067\t\tValidation Accuracy: 0.5100\n",
      "Epoch [23/30]\tTraining Loss: 0.2568\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 0.7061\t\tValidation Accuracy: 0.5100\n",
      "Epoch [24/30]\tTraining Loss: 0.2570\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 0.7010\t\tValidation Accuracy: 0.5200\n",
      "Epoch [25/30]\tTraining Loss: 0.2563\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 0.7007\t\tValidation Accuracy: 0.5200\n",
      "Epoch [26/30]\tTraining Loss: 0.2562\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 0.7056\t\tValidation Accuracy: 0.5000\n",
      "Epoch [27/30]\tTraining Loss: 0.2561\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 0.7084\t\tValidation Accuracy: 0.5000\n",
      "Epoch [28/30]\tTraining Loss: 0.2564\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 0.7055\t\tValidation Accuracy: 0.4900\n",
      "Epoch [29/30]\tTraining Loss: 0.2560\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 0.7019\t\tValidation Accuracy: 0.5100\n",
      "Epoch [30/30]\tTraining Loss: 0.2561\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 0.7035\t\tValidation Accuracy: 0.5000\n",
      "Best model:\tTraining Loss: 0.3222\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 0.6925\t\tValidation Accuracy: 0.5400\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04df5dc7eeab4bf6ba4a47672bd80b80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In-domain Accuracy: 0.4700\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa6105ef8a68477e9b3b2a1c11fee7da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out-domain Accuracy: 0.4700\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'In-domain Accuracy': 0.4699999988079071,\n",
       " 'Out-domain Accuracy': 0.4699999988079071}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"facebook/opt-125m\"\n",
    "epochs = 30\n",
    "lr = 1e-4\n",
    "\n",
    "compute_model_performance(model_name=model_name, train_dataset=train_dataset, validation_dataset=validation_dataset, \n",
    "                          indomain_dataset=indomain_dataset, outdomain_dataset=outdomain_dataset, epochs=epochs, lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: facebook/opt-350m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea9cfc67dd2543b0ad44a01c8db21655",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/20 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teacher Training Accuracy: 0.5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05252b2bef91456282e68acbdf8a16f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/20 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76d4cf01109441b5aea8724ee04fc67e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training student model:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hh/mw6819wx54d5l9fvfcxs1c2c0000gp/T/ipykernel_1910/1538307471.py:20: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments.\n",
      "  print(np.unique(np.array(pred), return_counts=True))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0]), array([100]))\n",
      "Epoch [1/30]\tTraining Loss: 3.5211\t\tTraining Accuracy: 0.5000\t\tValidation Loss: 13.8735\t\tValidation Accuracy: 0.4700\n",
      "(array([0]), array([100]))\n",
      "Epoch [2/30]\tTraining Loss: 50.1323\t\tTraining Accuracy: 0.5000\t\tValidation Loss: 2.9542\t\tValidation Accuracy: 0.4700\n",
      "(array([1]), array([100]))\n",
      "Epoch [3/30]\tTraining Loss: 9.6378\t\tTraining Accuracy: 0.5000\t\tValidation Loss: 2.4749\t\tValidation Accuracy: 0.5300\n",
      "(array([1]), array([100]))\n",
      "Epoch [4/30]\tTraining Loss: 7.6976\t\tTraining Accuracy: 0.5000\t\tValidation Loss: 1.0869\t\tValidation Accuracy: 0.5300\n",
      "(array([0]), array([100]))\n",
      "Epoch [5/30]\tTraining Loss: 3.0672\t\tTraining Accuracy: 0.5000\t\tValidation Loss: 2.0311\t\tValidation Accuracy: 0.4700\n",
      "(array([0]), array([100]))\n",
      "Epoch [6/30]\tTraining Loss: 6.9482\t\tTraining Accuracy: 0.5000\t\tValidation Loss: 0.7322\t\tValidation Accuracy: 0.4700\n",
      "(array([1]), array([100]))\n",
      "Epoch [7/30]\tTraining Loss: 2.1125\t\tTraining Accuracy: 0.5500\t\tValidation Loss: 0.8545\t\tValidation Accuracy: 0.5300\n",
      "(array([1]), array([100]))\n",
      "Epoch [8/30]\tTraining Loss: 2.4272\t\tTraining Accuracy: 0.5000\t\tValidation Loss: 0.9235\t\tValidation Accuracy: 0.5300\n",
      "(array([1]), array([100]))\n",
      "Epoch [9/30]\tTraining Loss: 2.6225\t\tTraining Accuracy: 0.5000\t\tValidation Loss: 0.7492\t\tValidation Accuracy: 0.5300\n",
      "(array([0]), array([100]))\n",
      "Epoch [10/30]\tTraining Loss: 2.0303\t\tTraining Accuracy: 0.5000\t\tValidation Loss: 0.6964\t\tValidation Accuracy: 0.4700\n",
      "(array([0]), array([100]))\n",
      "Epoch [11/30]\tTraining Loss: 1.8537\t\tTraining Accuracy: 0.9000\t\tValidation Loss: 0.7722\t\tValidation Accuracy: 0.4700\n",
      "(array([0, 1]), array([98,  2]))\n",
      "Epoch [12/30]\tTraining Loss: 2.0002\t\tTraining Accuracy: 0.5500\t\tValidation Loss: 0.7070\t\tValidation Accuracy: 0.4900\n",
      "(array([0, 1]), array([ 3, 97]))\n",
      "Epoch [13/30]\tTraining Loss: 1.5853\t\tTraining Accuracy: 0.9500\t\tValidation Loss: 0.6769\t\tValidation Accuracy: 0.5200\n",
      "(array([1]), array([100]))\n",
      "Epoch [14/30]\tTraining Loss: 1.2449\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 0.7783\t\tValidation Accuracy: 0.5300\n",
      "(array([0, 1]), array([11, 89]))\n",
      "Epoch [15/30]\tTraining Loss: 1.0868\t\tTraining Accuracy: 0.9500\t\tValidation Loss: 0.7086\t\tValidation Accuracy: 0.5800\n",
      "(array([0, 1]), array([68, 32]))\n",
      "Epoch [16/30]\tTraining Loss: 0.8080\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 0.6606\t\tValidation Accuracy: 0.5900\n",
      "(array([0, 1]), array([86, 14]))\n",
      "Epoch [17/30]\tTraining Loss: 0.6152\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 0.8552\t\tValidation Accuracy: 0.5700\n",
      "(array([0, 1]), array([88, 12]))\n",
      "Epoch [18/30]\tTraining Loss: 0.6432\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 0.9822\t\tValidation Accuracy: 0.5700\n",
      "(array([0, 1]), array([89, 11]))\n",
      "Epoch [19/30]\tTraining Loss: 0.7211\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 1.0766\t\tValidation Accuracy: 0.5600\n",
      "(array([0, 1]), array([95,  5]))\n",
      "Epoch [20/30]\tTraining Loss: 0.7218\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 1.0689\t\tValidation Accuracy: 0.5200\n",
      "(array([0, 1]), array([45, 55]))\n",
      "Epoch [21/30]\tTraining Loss: 0.7346\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 0.8810\t\tValidation Accuracy: 0.6200\n",
      "(array([0, 1]), array([ 8, 92]))\n",
      "Epoch [22/30]\tTraining Loss: 0.6426\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 1.4725\t\tValidation Accuracy: 0.5700\n",
      "(array([1]), array([100]))\n",
      "Epoch [23/30]\tTraining Loss: 0.6685\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 1.8359\t\tValidation Accuracy: 0.5300\n",
      "(array([1]), array([100]))\n",
      "Epoch [24/30]\tTraining Loss: 0.6601\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 1.7750\t\tValidation Accuracy: 0.5300\n",
      "(array([1]), array([100]))\n",
      "Epoch [25/30]\tTraining Loss: 0.6273\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 1.5267\t\tValidation Accuracy: 0.5300\n",
      "(array([1]), array([100]))\n",
      "Epoch [26/30]\tTraining Loss: 0.5963\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 1.2937\t\tValidation Accuracy: 0.5300\n",
      "(array([1]), array([100]))\n",
      "Epoch [27/30]\tTraining Loss: 0.6081\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 1.1858\t\tValidation Accuracy: 0.5300\n",
      "(array([1]), array([100]))\n",
      "Epoch [28/30]\tTraining Loss: 0.6265\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 1.2172\t\tValidation Accuracy: 0.5300\n",
      "(array([1]), array([100]))\n",
      "Epoch [29/30]\tTraining Loss: 0.6162\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 1.3225\t\tValidation Accuracy: 0.5300\n",
      "(array([1]), array([100]))\n",
      "Epoch [30/30]\tTraining Loss: 0.6019\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 1.4550\t\tValidation Accuracy: 0.5300\n",
      "(array([0, 1]), array([10, 10]))\n",
      "(array([0, 1]), array([68, 32]))\n",
      "Best model:\tTraining Loss: 0.0991\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 0.6606\t\tValidation Accuracy: 0.5900\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aed553b66f4d4346b176666050fdbb22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1]), array([76, 24]))\n",
      "In-domain Accuracy: 0.6300\n",
      "(array([0]), array([100]))\n",
      "Out-domain Accuracy: 0.4500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'In-domain Accuracy': 0.6299999952316284,\n",
       " 'Out-domain Accuracy': 0.44999998807907104}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"facebook/opt-350m\"\n",
    "epochs = 30\n",
    "lr = 1e-4\n",
    "\n",
    "compute_model_performance(model_name=model_name, train_dataset=train_dataset, validation_dataset=validation_dataset, \n",
    "                          indomain_dataset=indomain_dataset, outdomain_dataset=outdomain_dataset, epochs=epochs, lr=lr, alpha=0.5, beta=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: facebook/opt-1.3b\n",
      "Teacher Training Accuracy: 0.6000000238418579\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a91118694c4a4db2b3440a758f3e0e73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/20 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training student model:\n",
      "Epoch [1/30]\tTraining Loss: 1.0035\t\tTraining Accuracy: 0.5500\t\tValidation Loss: 15.2655\t\tValidation Accuracy: 0.4700\n",
      "Epoch [2/30]\tTraining Loss: 16.0440\t\tTraining Accuracy: 0.5000\t\tValidation Loss: 5.0899\t\tValidation Accuracy: 0.4700\n",
      "Epoch [3/30]\tTraining Loss: 4.9379\t\tTraining Accuracy: 0.5000\t\tValidation Loss: 2.4257\t\tValidation Accuracy: 0.5300\n",
      "Epoch [4/30]\tTraining Loss: 2.1476\t\tTraining Accuracy: 0.5000\t\tValidation Loss: 2.0918\t\tValidation Accuracy: 0.4700\n",
      "Epoch [5/30]\tTraining Loss: 2.0574\t\tTraining Accuracy: 0.5000\t\tValidation Loss: 1.3306\t\tValidation Accuracy: 0.5300\n",
      "Epoch [6/30]\tTraining Loss: 1.0255\t\tTraining Accuracy: 0.5000\t\tValidation Loss: 0.9905\t\tValidation Accuracy: 0.5300\n",
      "Epoch [7/30]\tTraining Loss: 0.6886\t\tTraining Accuracy: 0.5000\t\tValidation Loss: 0.8548\t\tValidation Accuracy: 0.4700\n",
      "Epoch [8/30]\tTraining Loss: 0.6918\t\tTraining Accuracy: 0.5000\t\tValidation Loss: 0.7352\t\tValidation Accuracy: 0.4700\n",
      "Epoch [9/30]\tTraining Loss: 0.5061\t\tTraining Accuracy: 0.7000\t\tValidation Loss: 0.9197\t\tValidation Accuracy: 0.5300\n",
      "Epoch [10/30]\tTraining Loss: 0.5251\t\tTraining Accuracy: 0.5000\t\tValidation Loss: 0.9119\t\tValidation Accuracy: 0.5300\n",
      "Epoch [11/30]\tTraining Loss: 0.4453\t\tTraining Accuracy: 0.6500\t\tValidation Loss: 0.6947\t\tValidation Accuracy: 0.5400\n",
      "Epoch [12/30]\tTraining Loss: 0.3137\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 0.7284\t\tValidation Accuracy: 0.5100\n",
      "Epoch [13/30]\tTraining Loss: 0.3425\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 0.6995\t\tValidation Accuracy: 0.5300\n",
      "Epoch [14/30]\tTraining Loss: 0.2290\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 0.8709\t\tValidation Accuracy: 0.5300\n",
      "Epoch [15/30]\tTraining Loss: 0.2082\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 1.0743\t\tValidation Accuracy: 0.5300\n",
      "Epoch [16/30]\tTraining Loss: 0.2142\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 1.0863\t\tValidation Accuracy: 0.5300\n",
      "Epoch [17/30]\tTraining Loss: 0.1947\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 1.0138\t\tValidation Accuracy: 0.5300\n",
      "Epoch [18/30]\tTraining Loss: 0.1988\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 0.9793\t\tValidation Accuracy: 0.5100\n",
      "Epoch [19/30]\tTraining Loss: 0.2062\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 0.9976\t\tValidation Accuracy: 0.5100\n",
      "Epoch [20/30]\tTraining Loss: 0.1992\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 1.0421\t\tValidation Accuracy: 0.5200\n",
      "Epoch [21/30]\tTraining Loss: 0.1899\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 1.0470\t\tValidation Accuracy: 0.5200\n",
      "Epoch [22/30]\tTraining Loss: 0.1890\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 0.9742\t\tValidation Accuracy: 0.5200\n",
      "Epoch [23/30]\tTraining Loss: 0.1851\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 0.8944\t\tValidation Accuracy: 0.5100\n",
      "Epoch [24/30]\tTraining Loss: 0.1859\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 0.8704\t\tValidation Accuracy: 0.5100\n",
      "Epoch [25/30]\tTraining Loss: 0.1861\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 0.8921\t\tValidation Accuracy: 0.5000\n",
      "Epoch [26/30]\tTraining Loss: 0.1842\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 0.9269\t\tValidation Accuracy: 0.5200\n",
      "Epoch [27/30]\tTraining Loss: 0.1845\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 0.9345\t\tValidation Accuracy: 0.5200\n",
      "Epoch [28/30]\tTraining Loss: 0.1839\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 0.9159\t\tValidation Accuracy: 0.5200\n",
      "Epoch [29/30]\tTraining Loss: 0.1832\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 0.9024\t\tValidation Accuracy: 0.5100\n",
      "Epoch [30/30]\tTraining Loss: 0.1835\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 0.9078\t\tValidation Accuracy: 0.5200\n",
      "Best model:\tTraining Loss: 0.3055\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 0.6947\t\tValidation Accuracy: 0.5400\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81763e9f18104c22a98d6fee4cb85d72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In-domain Accuracy: 0.4600\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "075ed43d1b03497b90e4af4afebc97ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out-domain Accuracy: 0.4800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'In-domain Accuracy': 0.46000000834465027,\n",
       " 'Out-domain Accuracy': 0.47999998927116394}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"facebook/opt-1.3b\"\n",
    "epochs = 30\n",
    "lr = 1e-4\n",
    "\n",
    "compute_model_performance(model_name=model_name, train_dataset=train_dataset, validation_dataset=validation_dataset, \n",
    "                          indomain_dataset=indomain_dataset, outdomain_dataset=outdomain_dataset, epochs=epochs, lr=lr, alpha=0.2, beta=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: facebook/opt-350m\n",
      "Teacher Training Accuracy: 0.5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b5fb74ed16c41e7a598ef3d33a96a0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/20 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training student model:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hh/mw6819wx54d5l9fvfcxs1c2c0000gp/T/ipykernel_1910/1538307471.py:20: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments.\n",
      "  print(np.unique(np.array(pred), return_counts=True))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0]), array([100]))\n",
      "Epoch [1/30]\tTraining Loss: 1.0550\t\tTraining Accuracy: 0.5000\t\tValidation Loss: 13.8726\t\tValidation Accuracy: 0.4700\n",
      "(array([0]), array([100]))\n",
      "Epoch [2/30]\tTraining Loss: 13.9399\t\tTraining Accuracy: 0.5000\t\tValidation Loss: 3.0408\t\tValidation Accuracy: 0.4700\n",
      "(array([1]), array([100]))\n",
      "Epoch [3/30]\tTraining Loss: 2.7493\t\tTraining Accuracy: 0.5000\t\tValidation Loss: 2.3803\t\tValidation Accuracy: 0.5300\n",
      "(array([1]), array([100]))\n",
      "Epoch [4/30]\tTraining Loss: 2.1754\t\tTraining Accuracy: 0.5000\t\tValidation Loss: 0.9579\t\tValidation Accuracy: 0.5300\n",
      "(array([0]), array([100]))\n",
      "Epoch [5/30]\tTraining Loss: 0.7758\t\tTraining Accuracy: 0.5000\t\tValidation Loss: 2.2721\t\tValidation Accuracy: 0.4700\n",
      "(array([0]), array([100]))\n",
      "Epoch [6/30]\tTraining Loss: 2.1644\t\tTraining Accuracy: 0.5000\t\tValidation Loss: 0.7624\t\tValidation Accuracy: 0.4700\n",
      "(array([1]), array([100]))\n",
      "Epoch [7/30]\tTraining Loss: 0.6092\t\tTraining Accuracy: 0.5500\t\tValidation Loss: 0.8514\t\tValidation Accuracy: 0.5300\n",
      "(array([1]), array([100]))\n",
      "Epoch [8/30]\tTraining Loss: 0.6930\t\tTraining Accuracy: 0.5000\t\tValidation Loss: 0.9262\t\tValidation Accuracy: 0.5300\n",
      "(array([1]), array([100]))\n",
      "Epoch [9/30]\tTraining Loss: 0.7457\t\tTraining Accuracy: 0.5000\t\tValidation Loss: 0.7358\t\tValidation Accuracy: 0.5300\n",
      "(array([0, 1]), array([97,  3]))\n",
      "Epoch [10/30]\tTraining Loss: 0.5408\t\tTraining Accuracy: 0.5000\t\tValidation Loss: 0.6943\t\tValidation Accuracy: 0.5000\n",
      "(array([0]), array([100]))\n",
      "Epoch [11/30]\tTraining Loss: 0.4670\t\tTraining Accuracy: 0.9500\t\tValidation Loss: 0.7857\t\tValidation Accuracy: 0.4700\n",
      "(array([0, 1]), array([91,  9]))\n",
      "Epoch [12/30]\tTraining Loss: 0.4738\t\tTraining Accuracy: 0.7500\t\tValidation Loss: 0.7104\t\tValidation Accuracy: 0.5600\n",
      "(array([0, 1]), array([34, 66]))\n",
      "Epoch [13/30]\tTraining Loss: 0.3335\t\tTraining Accuracy: 0.9500\t\tValidation Loss: 0.6395\t\tValidation Accuracy: 0.5900\n",
      "(array([0, 1]), array([10, 90]))\n",
      "Epoch [14/30]\tTraining Loss: 0.2128\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 0.7836\t\tValidation Accuracy: 0.5300\n",
      "(array([0, 1]), array([14, 86]))\n",
      "Epoch [15/30]\tTraining Loss: 0.1737\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 0.9032\t\tValidation Accuracy: 0.5700\n",
      "(array([0, 1]), array([25, 75]))\n",
      "Epoch [16/30]\tTraining Loss: 0.1481\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 0.8716\t\tValidation Accuracy: 0.5600\n",
      "(array([0, 1]), array([46, 54]))\n",
      "Epoch [17/30]\tTraining Loss: 0.1440\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 0.7541\t\tValidation Accuracy: 0.6300\n",
      "(array([0, 1]), array([63, 37]))\n",
      "Epoch [18/30]\tTraining Loss: 0.1574\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 0.7968\t\tValidation Accuracy: 0.6000\n",
      "(array([0, 1]), array([71, 29]))\n",
      "Epoch [19/30]\tTraining Loss: 0.1568\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 0.7914\t\tValidation Accuracy: 0.5800\n",
      "(array([0, 1]), array([82, 18]))\n",
      "Epoch [20/30]\tTraining Loss: 0.1422\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 0.7544\t\tValidation Accuracy: 0.5500\n",
      "(array([0, 1]), array([ 1, 99]))\n",
      "Epoch [21/30]\tTraining Loss: 0.1879\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 1.5731\t\tValidation Accuracy: 0.5400\n",
      "(array([1]), array([100]))\n",
      "Epoch [22/30]\tTraining Loss: 0.1625\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 2.1884\t\tValidation Accuracy: 0.5300\n",
      "(array([0, 1]), array([ 1, 99]))\n",
      "Epoch [23/30]\tTraining Loss: 0.1609\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 1.7232\t\tValidation Accuracy: 0.5400\n",
      "(array([0, 1]), array([ 8, 92]))\n",
      "Epoch [24/30]\tTraining Loss: 0.1530\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 1.2595\t\tValidation Accuracy: 0.5900\n",
      "(array([0, 1]), array([15, 85]))\n",
      "Epoch [25/30]\tTraining Loss: 0.1542\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 1.0533\t\tValidation Accuracy: 0.6400\n",
      "(array([0, 1]), array([12, 88]))\n",
      "Epoch [26/30]\tTraining Loss: 0.1451\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 1.0374\t\tValidation Accuracy: 0.6100\n",
      "(array([0, 1]), array([10, 90]))\n",
      "Epoch [27/30]\tTraining Loss: 0.1398\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 1.0289\t\tValidation Accuracy: 0.5900\n",
      "(array([0, 1]), array([ 8, 92]))\n",
      "Epoch [28/30]\tTraining Loss: 0.1414\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 1.0060\t\tValidation Accuracy: 0.5700\n",
      "(array([0, 1]), array([11, 89]))\n",
      "Epoch [29/30]\tTraining Loss: 0.1431\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 0.9450\t\tValidation Accuracy: 0.6000\n",
      "(array([0, 1]), array([18, 82]))\n",
      "Epoch [30/30]\tTraining Loss: 0.1399\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 0.8719\t\tValidation Accuracy: 0.6100\n",
      "(array([0, 1]), array([10, 10]))\n",
      "(array([0, 1]), array([34, 66]))\n",
      "Best model:\tTraining Loss: 0.1832\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 0.6395\t\tValidation Accuracy: 0.5900\n",
      "(array([0, 1]), array([40, 60]))\n",
      "In-domain Accuracy: 0.6100\n",
      "(array([0]), array([100]))\n",
      "Out-domain Accuracy: 0.4500\n",
      "Model: facebook/opt-350m\n",
      "Teacher Training Accuracy: 0.5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "230a3abf9b164f22a407bde43ab46797",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training student model:\n",
      "(array([0]), array([100]))\n",
      "Epoch [1/30]\tTraining Loss: 0.9407\t\tTraining Accuracy: 0.5000\t\tValidation Loss: 13.8782\t\tValidation Accuracy: 0.4700\n",
      "(array([0]), array([100]))\n",
      "Epoch [2/30]\tTraining Loss: 14.8383\t\tTraining Accuracy: 0.5000\t\tValidation Loss: 2.8256\t\tValidation Accuracy: 0.4700\n",
      "(array([1]), array([100]))\n",
      "Epoch [3/30]\tTraining Loss: 2.7323\t\tTraining Accuracy: 0.5000\t\tValidation Loss: 2.6002\t\tValidation Accuracy: 0.5300\n",
      "(array([1]), array([100]))\n",
      "Epoch [4/30]\tTraining Loss: 2.2161\t\tTraining Accuracy: 0.5000\t\tValidation Loss: 1.2239\t\tValidation Accuracy: 0.5300\n",
      "(array([0]), array([100]))\n",
      "Epoch [5/30]\tTraining Loss: 0.9615\t\tTraining Accuracy: 0.5000\t\tValidation Loss: 2.0627\t\tValidation Accuracy: 0.4700\n",
      "(array([0, 1]), array([75, 25]))\n",
      "Epoch [6/30]\tTraining Loss: 2.0901\t\tTraining Accuracy: 0.5000\t\tValidation Loss: 0.6977\t\tValidation Accuracy: 0.4000\n",
      "(array([1]), array([100]))\n",
      "Epoch [7/30]\tTraining Loss: 0.5677\t\tTraining Accuracy: 0.9000\t\tValidation Loss: 0.9192\t\tValidation Accuracy: 0.5300\n",
      "(array([1]), array([100]))\n",
      "Epoch [8/30]\tTraining Loss: 0.7341\t\tTraining Accuracy: 0.5000\t\tValidation Loss: 0.9067\t\tValidation Accuracy: 0.5300\n",
      "(array([1]), array([100]))\n",
      "Epoch [9/30]\tTraining Loss: 0.7190\t\tTraining Accuracy: 0.5000\t\tValidation Loss: 0.7174\t\tValidation Accuracy: 0.5300\n",
      "(array([0]), array([100]))\n",
      "Epoch [10/30]\tTraining Loss: 0.5610\t\tTraining Accuracy: 0.5000\t\tValidation Loss: 0.7218\t\tValidation Accuracy: 0.4700\n",
      "(array([0]), array([100]))\n",
      "Epoch [11/30]\tTraining Loss: 0.5924\t\tTraining Accuracy: 0.5500\t\tValidation Loss: 0.7489\t\tValidation Accuracy: 0.4700\n",
      "(array([0, 1]), array([46, 54]))\n",
      "Epoch [12/30]\tTraining Loss: 0.6081\t\tTraining Accuracy: 0.5500\t\tValidation Loss: 0.6907\t\tValidation Accuracy: 0.5500\n",
      "(array([1]), array([100]))\n",
      "Epoch [13/30]\tTraining Loss: 0.5064\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 0.7520\t\tValidation Accuracy: 0.5300\n",
      "(array([1]), array([100]))\n",
      "Epoch [14/30]\tTraining Loss: 0.5091\t\tTraining Accuracy: 0.5000\t\tValidation Loss: 0.7948\t\tValidation Accuracy: 0.5300\n",
      "(array([1]), array([100]))\n",
      "Epoch [15/30]\tTraining Loss: 0.4900\t\tTraining Accuracy: 0.5000\t\tValidation Loss: 0.7081\t\tValidation Accuracy: 0.5300\n",
      "(array([0, 1]), array([65, 35]))\n",
      "Epoch [16/30]\tTraining Loss: 0.3736\t\tTraining Accuracy: 0.9500\t\tValidation Loss: 0.6845\t\tValidation Accuracy: 0.5600\n",
      "(array([0, 1]), array([79, 21]))\n",
      "Epoch [17/30]\tTraining Loss: 0.2995\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 0.7405\t\tValidation Accuracy: 0.5200\n",
      "(array([0, 1]), array([64, 36]))\n",
      "Epoch [18/30]\tTraining Loss: 0.2469\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 0.7724\t\tValidation Accuracy: 0.5500\n",
      "(array([0, 1]), array([49, 51]))\n",
      "Epoch [19/30]\tTraining Loss: 0.2149\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 0.8958\t\tValidation Accuracy: 0.5800\n",
      "(array([0, 1]), array([37, 63]))\n",
      "Epoch [20/30]\tTraining Loss: 0.2176\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 1.1572\t\tValidation Accuracy: 0.5800\n",
      "(array([0, 1]), array([22, 78]))\n",
      "Epoch [21/30]\tTraining Loss: 0.2240\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 1.5029\t\tValidation Accuracy: 0.5700\n",
      "(array([0, 1]), array([ 5, 95]))\n",
      "Epoch [22/30]\tTraining Loss: 0.2217\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 1.8321\t\tValidation Accuracy: 0.5400\n",
      "(array([0, 1]), array([ 2, 98]))\n",
      "Epoch [23/30]\tTraining Loss: 0.2207\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 1.9465\t\tValidation Accuracy: 0.5300\n",
      "(array([0, 1]), array([ 2, 98]))\n",
      "Epoch [24/30]\tTraining Loss: 0.2247\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 1.7663\t\tValidation Accuracy: 0.5300\n",
      "(array([0, 1]), array([ 7, 93]))\n",
      "Epoch [25/30]\tTraining Loss: 0.2127\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 1.5108\t\tValidation Accuracy: 0.5200\n",
      "(array([0, 1]), array([12, 88]))\n",
      "Epoch [26/30]\tTraining Loss: 0.2056\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 1.3042\t\tValidation Accuracy: 0.5700\n",
      "(array([0, 1]), array([13, 87]))\n",
      "Epoch [27/30]\tTraining Loss: 0.2064\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 1.1665\t\tValidation Accuracy: 0.5800\n",
      "(array([0, 1]), array([12, 88]))\n",
      "Epoch [28/30]\tTraining Loss: 0.2093\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 1.1263\t\tValidation Accuracy: 0.5700\n",
      "(array([0, 1]), array([ 9, 91]))\n",
      "Epoch [29/30]\tTraining Loss: 0.2083\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 1.1714\t\tValidation Accuracy: 0.5400\n",
      "(array([0, 1]), array([ 6, 94]))\n",
      "Epoch [30/30]\tTraining Loss: 0.2054\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 1.2483\t\tValidation Accuracy: 0.5500\n",
      "(array([0, 1]), array([10, 10]))\n",
      "(array([0, 1]), array([65, 35]))\n",
      "Best model:\tTraining Loss: 0.2873\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 0.6845\t\tValidation Accuracy: 0.5600\n",
      "(array([0, 1]), array([73, 27]))\n",
      "In-domain Accuracy: 0.6000\n",
      "(array([0]), array([100]))\n",
      "Out-domain Accuracy: 0.4500\n",
      "Model: facebook/opt-350m\n",
      "Teacher Training Accuracy: 0.5\n",
      "Training student model:\n",
      "(array([0]), array([100]))\n",
      "Epoch [1/30]\tTraining Loss: 0.8263\t\tTraining Accuracy: 0.5000\t\tValidation Loss: 13.8898\t\tValidation Accuracy: 0.4700\n",
      "(array([0]), array([100]))\n",
      "Epoch [2/30]\tTraining Loss: 15.7438\t\tTraining Accuracy: 0.5000\t\tValidation Loss: 2.6355\t\tValidation Accuracy: 0.4700\n",
      "(array([1]), array([100]))\n",
      "Epoch [3/30]\tTraining Loss: 2.7005\t\tTraining Accuracy: 0.5000\t\tValidation Loss: 2.7818\t\tValidation Accuracy: 0.5300\n",
      "(array([1]), array([100]))\n",
      "Epoch [4/30]\tTraining Loss: 2.1700\t\tTraining Accuracy: 0.5000\t\tValidation Loss: 1.5117\t\tValidation Accuracy: 0.5300\n",
      "(array([0]), array([100]))\n",
      "Epoch [5/30]\tTraining Loss: 1.1026\t\tTraining Accuracy: 0.5000\t\tValidation Loss: 1.3529\t\tValidation Accuracy: 0.4700\n",
      "(array([1]), array([100]))\n",
      "Epoch [6/30]\tTraining Loss: 1.3905\t\tTraining Accuracy: 0.5000\t\tValidation Loss: 0.7438\t\tValidation Accuracy: 0.5300\n",
      "(array([1]), array([100]))\n",
      "Epoch [7/30]\tTraining Loss: 0.5359\t\tTraining Accuracy: 0.5000\t\tValidation Loss: 0.9171\t\tValidation Accuracy: 0.5300\n",
      "(array([1]), array([100]))\n",
      "Epoch [8/30]\tTraining Loss: 0.6539\t\tTraining Accuracy: 0.5000\t\tValidation Loss: 0.8175\t\tValidation Accuracy: 0.5300\n",
      "(array([1]), array([100]))\n",
      "Epoch [9/30]\tTraining Loss: 0.5805\t\tTraining Accuracy: 0.5000\t\tValidation Loss: 0.6929\t\tValidation Accuracy: 0.5300\n",
      "(array([0]), array([100]))\n",
      "Epoch [10/30]\tTraining Loss: 0.5212\t\tTraining Accuracy: 0.5000\t\tValidation Loss: 0.7069\t\tValidation Accuracy: 0.4700\n",
      "(array([0, 1]), array([ 5, 95]))\n",
      "Epoch [11/30]\tTraining Loss: 0.5672\t\tTraining Accuracy: 0.5500\t\tValidation Loss: 0.6907\t\tValidation Accuracy: 0.5400\n",
      "(array([1]), array([100]))\n",
      "Epoch [12/30]\tTraining Loss: 0.5163\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 0.7332\t\tValidation Accuracy: 0.5300\n",
      "(array([1]), array([100]))\n",
      "Epoch [13/30]\tTraining Loss: 0.4997\t\tTraining Accuracy: 0.5000\t\tValidation Loss: 0.7876\t\tValidation Accuracy: 0.5300\n",
      "(array([1]), array([100]))\n",
      "Epoch [14/30]\tTraining Loss: 0.5097\t\tTraining Accuracy: 0.5000\t\tValidation Loss: 0.7293\t\tValidation Accuracy: 0.5300\n",
      "(array([0, 1]), array([33, 67]))\n",
      "Epoch [15/30]\tTraining Loss: 0.4439\t\tTraining Accuracy: 0.5000\t\tValidation Loss: 0.6845\t\tValidation Accuracy: 0.5800\n",
      "(array([0, 1]), array([68, 32]))\n",
      "Epoch [16/30]\tTraining Loss: 0.3953\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 0.6805\t\tValidation Accuracy: 0.5700\n",
      "(array([0, 1]), array([ 9, 91]))\n",
      "Epoch [17/30]\tTraining Loss: 0.3326\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 0.7229\t\tValidation Accuracy: 0.5400\n",
      "(array([0, 1]), array([ 1, 99]))\n",
      "Epoch [18/30]\tTraining Loss: 0.2619\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 1.0693\t\tValidation Accuracy: 0.5200\n",
      "(array([0, 1]), array([ 1, 99]))\n",
      "Epoch [19/30]\tTraining Loss: 0.2457\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 1.3484\t\tValidation Accuracy: 0.5200\n",
      "(array([0, 1]), array([ 1, 99]))\n",
      "Epoch [20/30]\tTraining Loss: 0.2474\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 1.5524\t\tValidation Accuracy: 0.5200\n",
      "(array([1]), array([100]))\n",
      "Epoch [21/30]\tTraining Loss: 0.2559\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 1.6599\t\tValidation Accuracy: 0.5300\n",
      "(array([1]), array([100]))\n",
      "Epoch [22/30]\tTraining Loss: 0.2475\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 1.5077\t\tValidation Accuracy: 0.5300\n",
      "(array([0, 1]), array([ 3, 97]))\n",
      "Epoch [23/30]\tTraining Loss: 0.2512\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 1.0505\t\tValidation Accuracy: 0.5200\n",
      "(array([0, 1]), array([10, 90]))\n",
      "Epoch [24/30]\tTraining Loss: 0.2725\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 0.9485\t\tValidation Accuracy: 0.5700\n",
      "(array([1]), array([100]))\n",
      "Epoch [25/30]\tTraining Loss: 0.2521\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 1.0431\t\tValidation Accuracy: 0.5300\n",
      "(array([0, 1]), array([ 1, 99]))\n",
      "Epoch [26/30]\tTraining Loss: 0.2502\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 0.8940\t\tValidation Accuracy: 0.5400\n",
      "(array([0, 1]), array([60, 40]))\n",
      "Epoch [27/30]\tTraining Loss: 0.2527\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 0.7496\t\tValidation Accuracy: 0.5700\n",
      "(array([0, 1]), array([77, 23]))\n",
      "Epoch [28/30]\tTraining Loss: 0.2401\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 0.7721\t\tValidation Accuracy: 0.5600\n",
      "(array([0, 1]), array([86, 14]))\n",
      "Epoch [29/30]\tTraining Loss: 0.2485\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 0.7816\t\tValidation Accuracy: 0.4900\n",
      "(array([0, 1]), array([87, 13]))\n",
      "Epoch [30/30]\tTraining Loss: 0.2460\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 0.7406\t\tValidation Accuracy: 0.4800\n",
      "(array([0, 1]), array([10, 10]))\n",
      "(array([0, 1]), array([68, 32]))\n",
      "Best model:\tTraining Loss: 0.3442\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 0.6805\t\tValidation Accuracy: 0.5700\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b1e46e14a0342139a4ddaa76c842c0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1]), array([67, 33]))\n",
      "In-domain Accuracy: 0.5400\n",
      "(array([0]), array([100]))\n",
      "Out-domain Accuracy: 0.4500\n",
      "Model: facebook/opt-350m\n",
      "Teacher Training Accuracy: 0.5\n",
      "Training student model:\n",
      "(array([0]), array([100]))\n",
      "Epoch [1/30]\tTraining Loss: 0.7119\t\tTraining Accuracy: 0.5000\t\tValidation Loss: 13.9004\t\tValidation Accuracy: 0.4700\n",
      "(array([0]), array([100]))\n",
      "Epoch [2/30]\tTraining Loss: 16.6480\t\tTraining Accuracy: 0.5000\t\tValidation Loss: 2.4665\t\tValidation Accuracy: 0.4700\n",
      "(array([1]), array([100]))\n",
      "Epoch [3/30]\tTraining Loss: 2.6588\t\tTraining Accuracy: 0.5000\t\tValidation Loss: 2.9531\t\tValidation Accuracy: 0.5300\n",
      "(array([1]), array([100]))\n",
      "Epoch [4/30]\tTraining Loss: 2.0794\t\tTraining Accuracy: 0.5000\t\tValidation Loss: 1.8406\t\tValidation Accuracy: 0.5300\n",
      "(array([0]), array([100]))\n",
      "Epoch [5/30]\tTraining Loss: 1.2146\t\tTraining Accuracy: 0.5000\t\tValidation Loss: 0.8420\t\tValidation Accuracy: 0.4700\n",
      "(array([1]), array([100]))\n",
      "Epoch [6/30]\tTraining Loss: 0.7781\t\tTraining Accuracy: 0.5000\t\tValidation Loss: 0.8250\t\tValidation Accuracy: 0.5300\n",
      "(array([1]), array([100]))\n",
      "Epoch [7/30]\tTraining Loss: 0.5085\t\tTraining Accuracy: 0.5000\t\tValidation Loss: 0.8663\t\tValidation Accuracy: 0.5300\n",
      "(array([1]), array([100]))\n",
      "Epoch [8/30]\tTraining Loss: 0.5321\t\tTraining Accuracy: 0.5000\t\tValidation Loss: 0.7376\t\tValidation Accuracy: 0.5300\n",
      "(array([1]), array([100]))\n",
      "Epoch [9/30]\tTraining Loss: 0.4731\t\tTraining Accuracy: 0.5000\t\tValidation Loss: 0.6924\t\tValidation Accuracy: 0.5300\n",
      "(array([1]), array([100]))\n",
      "Epoch [10/30]\tTraining Loss: 0.4946\t\tTraining Accuracy: 0.6000\t\tValidation Loss: 0.6930\t\tValidation Accuracy: 0.5300\n",
      "(array([1]), array([100]))\n",
      "Epoch [11/30]\tTraining Loss: 0.4793\t\tTraining Accuracy: 0.5000\t\tValidation Loss: 0.7441\t\tValidation Accuracy: 0.5300\n",
      "(array([1]), array([100]))\n",
      "Epoch [12/30]\tTraining Loss: 0.4635\t\tTraining Accuracy: 0.5000\t\tValidation Loss: 0.7966\t\tValidation Accuracy: 0.5300\n",
      "(array([1]), array([100]))\n",
      "Epoch [13/30]\tTraining Loss: 0.4777\t\tTraining Accuracy: 0.5000\t\tValidation Loss: 0.7445\t\tValidation Accuracy: 0.5300\n",
      "(array([1]), array([100]))\n",
      "Epoch [14/30]\tTraining Loss: 0.4468\t\tTraining Accuracy: 0.5000\t\tValidation Loss: 0.6945\t\tValidation Accuracy: 0.5300\n",
      "(array([1]), array([100]))\n",
      "Epoch [15/30]\tTraining Loss: 0.4372\t\tTraining Accuracy: 0.5500\t\tValidation Loss: 0.6924\t\tValidation Accuracy: 0.5300\n",
      "(array([1]), array([100]))\n",
      "Epoch [16/30]\tTraining Loss: 0.4185\t\tTraining Accuracy: 0.9000\t\tValidation Loss: 0.7466\t\tValidation Accuracy: 0.5300\n",
      "(array([1]), array([100]))\n",
      "Epoch [17/30]\tTraining Loss: 0.3826\t\tTraining Accuracy: 0.5000\t\tValidation Loss: 0.7857\t\tValidation Accuracy: 0.5300\n",
      "(array([0, 1]), array([ 1, 99]))\n",
      "Epoch [18/30]\tTraining Loss: 0.3472\t\tTraining Accuracy: 0.5000\t\tValidation Loss: 0.7101\t\tValidation Accuracy: 0.5200\n",
      "(array([0, 1]), array([30, 70]))\n",
      "Epoch [19/30]\tTraining Loss: 0.2990\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 0.7149\t\tValidation Accuracy: 0.5900\n",
      "(array([0, 1]), array([ 7, 93]))\n",
      "Epoch [20/30]\tTraining Loss: 0.2709\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 0.8124\t\tValidation Accuracy: 0.5400\n",
      "(array([1]), array([100]))\n",
      "Epoch [21/30]\tTraining Loss: 0.2563\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 1.1616\t\tValidation Accuracy: 0.5300\n",
      "(array([1]), array([100]))\n",
      "Epoch [22/30]\tTraining Loss: 0.2629\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 1.4570\t\tValidation Accuracy: 0.5300\n",
      "(array([1]), array([100]))\n",
      "Epoch [23/30]\tTraining Loss: 0.2686\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 1.4907\t\tValidation Accuracy: 0.5300\n",
      "(array([1]), array([100]))\n",
      "Epoch [24/30]\tTraining Loss: 0.2684\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 1.5028\t\tValidation Accuracy: 0.5300\n",
      "(array([1]), array([100]))\n",
      "Epoch [25/30]\tTraining Loss: 0.2606\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 1.2320\t\tValidation Accuracy: 0.5300\n",
      "(array([1]), array([100]))\n",
      "Epoch [26/30]\tTraining Loss: 0.2559\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 1.0925\t\tValidation Accuracy: 0.5300\n",
      "(array([1]), array([100]))\n",
      "Epoch [27/30]\tTraining Loss: 0.2611\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 1.0479\t\tValidation Accuracy: 0.5300\n",
      "(array([1]), array([100]))\n",
      "Epoch [28/30]\tTraining Loss: 0.2637\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 1.3067\t\tValidation Accuracy: 0.5300\n",
      "(array([0, 1]), array([15, 85]))\n",
      "Epoch [29/30]\tTraining Loss: 0.2792\t\tTraining Accuracy: 0.8000\t\tValidation Loss: 0.9052\t\tValidation Accuracy: 0.5600\n",
      "(array([0, 1]), array([23, 77]))\n",
      "Epoch [30/30]\tTraining Loss: 0.2945\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 0.9094\t\tValidation Accuracy: 0.5400\n",
      "(array([0, 1]), array([ 2, 18]))\n",
      "(array([1]), array([100]))\n",
      "Best model:\tTraining Loss: 0.6575\t\tTraining Accuracy: 0.6000\t\tValidation Loss: 0.6924\t\tValidation Accuracy: 0.5300\n",
      "(array([1]), array([100]))\n",
      "In-domain Accuracy: 0.4500\n",
      "(array([1]), array([100]))\n",
      "Out-domain Accuracy: 0.5500\n",
      "[0.6100000143051147, 0.6000000238418579, 0.5400000214576721, 0.44999998807907104]\n",
      "[0.44999998807907104, 0.44999998807907104, 0.44999998807907104, 0.550000011920929]\n"
     ]
    }
   ],
   "source": [
    "alphas = [0.1, 0.2, 0.3, 0.4]\n",
    "id_acc = []\n",
    "od_acc = []\n",
    "for alpha in alphas:\n",
    "    model_name = \"facebook/opt-350m\"\n",
    "    epochs = 30\n",
    "    lr = 1e-4\n",
    "    beta = 1 - alpha\n",
    "\n",
    "    acc_dict = compute_model_performance(model_name=model_name, train_dataset=train_dataset, validation_dataset=validation_dataset, \n",
    "                            indomain_dataset=indomain_dataset, outdomain_dataset=outdomain_dataset, epochs=epochs, lr=lr, alpha=alpha, beta=beta)\n",
    "    id_acc.append(acc_dict[\"In-domain Accuracy\"])\n",
    "    od_acc.append(acc_dict[\"Out-domain Accuracy\"])\n",
    "\n",
    "print(id_acc)\n",
    "print(od_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: facebook/opt-125m\n",
      "Teacher Training Accuracy: 0.5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c44e171d5a5f45b98dd4a19c064be090",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/20 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training student model:\n",
      "Epoch [1/30]\tTraining Loss: 0.6885\t\tTraining Accuracy: 0.4000\t\tValidation Loss: 0.7521\t\tValidation Accuracy: 0.5200\n",
      "Epoch [2/30]\tTraining Loss: 0.5446\t\tTraining Accuracy: 0.5500\t\tValidation Loss: 0.7902\t\tValidation Accuracy: 0.4700\n",
      "Epoch [3/30]\tTraining Loss: 0.4974\t\tTraining Accuracy: 0.6000\t\tValidation Loss: 0.7293\t\tValidation Accuracy: 0.5300\n",
      "Epoch [4/30]\tTraining Loss: 0.3364\t\tTraining Accuracy: 0.9500\t\tValidation Loss: 0.7927\t\tValidation Accuracy: 0.5300\n",
      "Epoch [5/30]\tTraining Loss: 0.2725\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 0.7032\t\tValidation Accuracy: 0.4700\n",
      "Epoch [6/30]\tTraining Loss: 0.2149\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 0.7310\t\tValidation Accuracy: 0.5500\n",
      "Epoch [7/30]\tTraining Loss: 0.2370\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 0.7505\t\tValidation Accuracy: 0.4600\n",
      "Epoch [8/30]\tTraining Loss: 0.2404\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 0.8585\t\tValidation Accuracy: 0.5500\n",
      "Epoch [9/30]\tTraining Loss: 0.2176\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 0.8296\t\tValidation Accuracy: 0.5500\n",
      "Epoch [10/30]\tTraining Loss: 0.2135\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 0.7508\t\tValidation Accuracy: 0.4800\n",
      "Epoch [11/30]\tTraining Loss: 0.2040\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 0.7454\t\tValidation Accuracy: 0.4300\n",
      "Epoch [12/30]\tTraining Loss: 0.2157\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 0.7337\t\tValidation Accuracy: 0.4700\n",
      "Epoch [13/30]\tTraining Loss: 0.2034\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 0.7442\t\tValidation Accuracy: 0.5200\n",
      "Epoch [14/30]\tTraining Loss: 0.2063\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 0.7559\t\tValidation Accuracy: 0.5200\n",
      "Epoch [15/30]\tTraining Loss: 0.2035\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 0.7510\t\tValidation Accuracy: 0.5200\n",
      "Epoch [16/30]\tTraining Loss: 0.1941\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 0.7522\t\tValidation Accuracy: 0.4600\n",
      "Epoch [17/30]\tTraining Loss: 0.1963\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 0.7545\t\tValidation Accuracy: 0.4700\n",
      "Epoch [18/30]\tTraining Loss: 0.1977\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 0.7594\t\tValidation Accuracy: 0.4800\n",
      "Epoch [19/30]\tTraining Loss: 0.1958\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 0.7713\t\tValidation Accuracy: 0.5100\n",
      "Epoch [20/30]\tTraining Loss: 0.1941\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 0.7831\t\tValidation Accuracy: 0.5100\n",
      "Epoch [21/30]\tTraining Loss: 0.1956\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 0.7802\t\tValidation Accuracy: 0.5100\n",
      "Epoch [22/30]\tTraining Loss: 0.1959\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 0.7650\t\tValidation Accuracy: 0.5000\n",
      "Epoch [23/30]\tTraining Loss: 0.1936\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 0.7531\t\tValidation Accuracy: 0.4800\n",
      "Epoch [24/30]\tTraining Loss: 0.1931\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 0.7493\t\tValidation Accuracy: 0.4600\n",
      "Epoch [25/30]\tTraining Loss: 0.1943\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 0.7502\t\tValidation Accuracy: 0.4700\n",
      "Epoch [26/30]\tTraining Loss: 0.1939\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 0.7555\t\tValidation Accuracy: 0.4700\n",
      "Epoch [27/30]\tTraining Loss: 0.1930\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 0.7637\t\tValidation Accuracy: 0.5000\n",
      "Epoch [28/30]\tTraining Loss: 0.1934\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 0.7675\t\tValidation Accuracy: 0.5100\n",
      "Epoch [29/30]\tTraining Loss: 0.1938\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 0.7631\t\tValidation Accuracy: 0.5000\n",
      "Epoch [30/30]\tTraining Loss: 0.1930\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 0.7557\t\tValidation Accuracy: 0.4800\n",
      "Best model:\tTraining Loss: 0.1006\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 0.7032\t\tValidation Accuracy: 0.4700\n",
      "In-domain Accuracy: 0.5400\n",
      "Out-domain Accuracy: 0.4700\n",
      "Model: facebook/opt-350m\n",
      "Teacher Training Accuracy: 0.5\n",
      "Training student model:\n",
      "Epoch [1/30]\tTraining Loss: 0.9407\t\tTraining Accuracy: 0.5000\t\tValidation Loss: 13.8782\t\tValidation Accuracy: 0.4700\n",
      "Epoch [2/30]\tTraining Loss: 14.8383\t\tTraining Accuracy: 0.5000\t\tValidation Loss: 2.8256\t\tValidation Accuracy: 0.4700\n",
      "Epoch [3/30]\tTraining Loss: 2.7323\t\tTraining Accuracy: 0.5000\t\tValidation Loss: 2.6002\t\tValidation Accuracy: 0.5300\n",
      "Epoch [4/30]\tTraining Loss: 2.2161\t\tTraining Accuracy: 0.5000\t\tValidation Loss: 1.2239\t\tValidation Accuracy: 0.5300\n",
      "Epoch [5/30]\tTraining Loss: 0.9615\t\tTraining Accuracy: 0.5000\t\tValidation Loss: 2.0627\t\tValidation Accuracy: 0.4700\n",
      "Epoch [6/30]\tTraining Loss: 2.0901\t\tTraining Accuracy: 0.5000\t\tValidation Loss: 0.6977\t\tValidation Accuracy: 0.4000\n",
      "Epoch [7/30]\tTraining Loss: 0.5677\t\tTraining Accuracy: 0.9000\t\tValidation Loss: 0.9192\t\tValidation Accuracy: 0.5300\n",
      "Epoch [8/30]\tTraining Loss: 0.7341\t\tTraining Accuracy: 0.5000\t\tValidation Loss: 0.9067\t\tValidation Accuracy: 0.5300\n",
      "Epoch [9/30]\tTraining Loss: 0.7190\t\tTraining Accuracy: 0.5000\t\tValidation Loss: 0.7174\t\tValidation Accuracy: 0.5300\n",
      "Epoch [10/30]\tTraining Loss: 0.5610\t\tTraining Accuracy: 0.5000\t\tValidation Loss: 0.7218\t\tValidation Accuracy: 0.4700\n",
      "Epoch [11/30]\tTraining Loss: 0.5924\t\tTraining Accuracy: 0.5500\t\tValidation Loss: 0.7489\t\tValidation Accuracy: 0.4700\n",
      "Epoch [12/30]\tTraining Loss: 0.6081\t\tTraining Accuracy: 0.5500\t\tValidation Loss: 0.6907\t\tValidation Accuracy: 0.5500\n",
      "Epoch [13/30]\tTraining Loss: 0.5064\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 0.7520\t\tValidation Accuracy: 0.5300\n",
      "Epoch [14/30]\tTraining Loss: 0.5091\t\tTraining Accuracy: 0.5000\t\tValidation Loss: 0.7948\t\tValidation Accuracy: 0.5300\n",
      "Epoch [15/30]\tTraining Loss: 0.4900\t\tTraining Accuracy: 0.5000\t\tValidation Loss: 0.7081\t\tValidation Accuracy: 0.5300\n",
      "Epoch [16/30]\tTraining Loss: 0.3736\t\tTraining Accuracy: 0.9500\t\tValidation Loss: 0.6845\t\tValidation Accuracy: 0.5600\n",
      "Epoch [17/30]\tTraining Loss: 0.2995\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 0.7405\t\tValidation Accuracy: 0.5200\n",
      "Epoch [18/30]\tTraining Loss: 0.2469\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 0.7724\t\tValidation Accuracy: 0.5500\n",
      "Epoch [19/30]\tTraining Loss: 0.2149\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 0.8958\t\tValidation Accuracy: 0.5800\n",
      "Epoch [20/30]\tTraining Loss: 0.2176\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 1.1572\t\tValidation Accuracy: 0.5800\n",
      "Epoch [21/30]\tTraining Loss: 0.2240\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 1.5029\t\tValidation Accuracy: 0.5700\n",
      "Epoch [22/30]\tTraining Loss: 0.2217\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 1.8321\t\tValidation Accuracy: 0.5400\n",
      "Epoch [23/30]\tTraining Loss: 0.2207\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 1.9465\t\tValidation Accuracy: 0.5300\n",
      "Epoch [24/30]\tTraining Loss: 0.2247\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 1.7663\t\tValidation Accuracy: 0.5300\n",
      "Epoch [25/30]\tTraining Loss: 0.2127\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 1.5108\t\tValidation Accuracy: 0.5200\n",
      "Epoch [26/30]\tTraining Loss: 0.2056\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 1.3042\t\tValidation Accuracy: 0.5700\n",
      "Epoch [27/30]\tTraining Loss: 0.2064\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 1.1665\t\tValidation Accuracy: 0.5800\n",
      "Epoch [28/30]\tTraining Loss: 0.2093\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 1.1263\t\tValidation Accuracy: 0.5700\n",
      "Epoch [29/30]\tTraining Loss: 0.2083\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 1.1714\t\tValidation Accuracy: 0.5400\n",
      "Epoch [30/30]\tTraining Loss: 0.2054\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 1.2483\t\tValidation Accuracy: 0.5500\n",
      "Best model:\tTraining Loss: 0.2873\t\tTraining Accuracy: 1.0000\t\tValidation Loss: 0.6845\t\tValidation Accuracy: 0.5600\n",
      "In-domain Accuracy: 0.6000\n",
      "Out-domain Accuracy: 0.4500\n",
      "Model: facebook/opt-1.3b\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47910429433d4a04a35d3b47b4f1defa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/20 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teacher Training Accuracy: 0.6000000238418579\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0555038d1f994224846ddb65b78aeb7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/20 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5152fa272a24d259f7ae09d67a08a21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training student model:\n",
      "Epoch [1/30]\tTraining Loss: 1.0035\t\tTraining Accuracy: 0.5500\t\tValidation Loss: 15.2655\t\tValidation Accuracy: 0.4700\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "models = [\n",
    "    \"facebook/opt-125m\",\n",
    "    \"facebook/opt-350m\",\n",
    "    \"facebook/opt-1.3b\",\n",
    "    \"facebook/opt-2.7b\"\n",
    "]\n",
    "\n",
    "acc_dict = {}\n",
    "epochs = 30\n",
    "lr = 1e-4\n",
    "alpha = 0.2\n",
    "beta = 0.8\n",
    "for model_name in models:\n",
    "    \n",
    "    acc = compute_model_performance(model_name=model_name, train_dataset=train_dataset, validation_dataset=validation_dataset, \n",
    "                            indomain_dataset=indomain_dataset, outdomain_dataset=outdomain_dataset, epochs=epochs, lr=lr, alpha=alpha, beta=beta)\n",
    "    acc_dict[model_name] = acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs7643-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
